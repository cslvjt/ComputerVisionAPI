{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化光流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import flow_to_image\n",
    "from einops import rearrange\n",
    "import torchvision.transforms.functional as tf\n",
    "def flow2img(flow,name):\n",
    "    \"\"\"\n",
    "    flow: h w 2\n",
    "    \"\"\"\n",
    "    flow = rearrange(flow,\"h w c -> c h w\")\n",
    "    flow_im = flow_to_image(flow)\n",
    "    image = tf.to_pil_image(flow_im)\n",
    "    image.save(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化模型特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reference:\n",
    "+ https://blog.csdn.net/weixin_45826022/article/details/118830531\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as tf\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "from einops import rearrange\n",
    "from archs.MIMOUNetV1 import MIMOUNet\n",
    "\n",
    "def read_img(img_path):\n",
    "    \"\"\"\n",
    "    return:\n",
    "        torch.Tensor: b c h w\n",
    "    \"\"\"\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB).astype(\"float32\")\n",
    "    img = torch.from_numpy(img.transpose(2,0,1)).float()/255.0\n",
    "    return img.unsqueeze(0)\n",
    "\n",
    "def tensor2img(tensor,name):\n",
    "    \"\"\"\n",
    "    tensor:\n",
    "        c h w\n",
    "    \"\"\"\n",
    "    image = tf.to_pil_image(tensor)\n",
    "    image.save(name)\n",
    "\n",
    "def show_feature_gray(feature, name):\n",
    "    \"\"\"\n",
    "    feature:\n",
    "        c h w\n",
    "    \"\"\"\n",
    "    feature = rearrange(feature[0], \"(c1 c2) h w -> (c1 h) (c2 w)\", c1=16)\n",
    "    feature = feature.unsqueeze(0)\n",
    "    print(feature.shape)\n",
    "    tensor2img(feature,name)\n",
    "\n",
    "def load_feature(model_path, img_path):\n",
    "    state_dict = torch.load(model_path)\n",
    "    model = MIMOUNet([4,8,12],[32,64,128],True)\n",
    "    model.load_state_dict(state_dict['params'])\n",
    "    model.eval()\n",
    "    input_image = read_img(img_path)\n",
    "    feature = model(input_image)\n",
    "    return feature\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # feature = torch.randn(64,256,256)\n",
    "    # show_feature_gray(feature, \"test.png\")\n",
    "    weight_path = \"weights/MIMOV1_600000.pth\"\n",
    "    img_path = \"testmini/blur/1.png\"\n",
    "    feature_list = load_feature(weight_path, img_path)\n",
    "    for feature in feature_list:\n",
    "        for key,val in feature.items():\n",
    "            feature_path = f\"feature_show/1/{key}.png\"\n",
    "            feauter_img = val\n",
    "            show_feature_gray(feauter_img, feature_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
